[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/CibnTZFQ)

# Project 2 Report

Read the [project 2
specification](https://github.com/COMP30019/Project-2-Specification) for
details on what needs to be covered here. You may modify this template as you see fit, but please
keep the same general structure and headings.

Remember that you must also continue to maintain the Game Design Document (GDD)
in the `GDD.md` file (as discussed in the specification). We've provided a
placeholder for it [here](GDD.md).

## Table of Contents

* [Evaluation Plan](#evaluation-plan)
* [Evaluation Report](#evaluation-report)
* [Shaders and Special Effects](#shaders-and-special-effects)
* [Summary of Contributions](#summary-of-contributions)
* [References and External Resources](#references-and-external-resources)


## Evaluation Plan

### 1.0 Goals with evaluation

The primary objective of this evaluation is to enhance the game by taking insights from real-life players. During the development stage, particular bugs or issues can be overlooked and this evaluation serves as a mechanism to identify, address and improve upon them.

Furthermore we seek to enhance the overall entertainment value of the game itself by actively incorporating player feedback. Our aim is to make the game not just technically sound but also as enjoyable and engaging as it can be.

--- 

### 2.0 Evaluation techniques: Which evaluation techniques will you use and why? What tasks will you ask participants to perform?

In order to comprehensively evaluate the game we will employ a range of assessment techniques. 
Players will rate their fear levels during gameplay and provide a gauge for the games immersion and suspenseful elements. 
Additionally we will inquire about overall satisfaction throughout the game to gauge user experience. 

Play testing will be done where players can provide insights. Play tests can be done once or multiple times.  We will ask participants to explore the map as well as try to survive the game for the entire 5 minutes.

---

### 3.0 Participants: How will you recruit participants? What qualifying criteria will you use to ensure that they are representative of your target audience?

Our game follows a horror theme and due to this we aim for an older audience that likes the fear factor. We aim to find participants through friends and family as well as possibly online on online gaming forums that are horror themed targeted. 

Some qualifying criterias will be:

**Age**: Due to horror aspect 15+ is preferred <br>
**Previous gaming experience**: Whether or not they regularly play games or not <br>
**Interest in the horror genre**: This is important as this is our target audience

Target audience is those who love survival horror games with an emphasis on narrative. Ensure participants have played at least one game from the genre in the past year. They should range from casual to hardcore gamers to capture a broad spectrum of feedback.

---

### 4.0 Data collection: What sort of data is being collected? How will you collect the data? What tools will you use?

We will collect data on these certain features:

Completion status: If they were able to survive the 5 minutes or not <br>
Ratings and feedback: overall satisfaction and enjoyment of the game <br>
Fear factor: Rating whether or not the horror theme was implemented well or not 

We plan on collecting the data in both ways; quantitative and qualitative. This involves aspects such as player feedback and comments, or game completion time, number of deaths and more. 

Data will be collected using game analytics tools to capture gameplay metrics automatically, and for feedback we will be utilising survey platforms for focus groups.

Tools we will be using include Unity Analytics for in-game data, and SurveyMonkey or Google Forms for feedback collection.

---

### 5.0 Data analysis: How will you analyse the data? What metrics will you use to evaluate your game, and provide a basis for making changes?

Metrics will be evaluated accordingly:

**5.1 Quantitative Analysis** <br>
Survival rate: Percentage of players able to complete game <br>
Fear ratings: Whether or not they found it suspenseful and scary <br>
Satisfaction: Average rating of game <br>
Number of tries to complete <br>
Number of items collected <br>

**5.2 Qualitative Analysis** <br>
Categorise feedback into themes (prioritise based on frequency and severity of issues mentioned) <br>
Gameplay <br>
Story <br>
Graphics <br>

**5.3 Metrics** <br>
Player retention rate <br>
Overall satisfaction score <br>
Perceived difficulty level <br>
Narrative engagement score <br>

According to these we will analyse the data and identify patterns or key areas that need improvements. 

---

### 6.0 Timeline: What is your timeline for completing the evaluation? When will you make changes to the game?

**Day 1-2**: Recruitment and evaluation of participants <br>
**Day 3-4**: Gameplay sessions and data collection <br>
**Day 5-6**: Data analysis and reports <br>
**Day 7+**: Changes and improvements to the game. <br>

---

### 7.0 Responsibilities: Who is responsible for each task? How will you ensure that everyone contributes equally?

#### 7.1 Evaluation organisation: 

Playtesting: Game testers and volunteer participants.

Feedback Collection: Kaiyuan Cui

Data Analysis: John An

Participant recruitment: Natasha Ngo

Implementation of Changes: Developers/ Full team members

#### 7.2 Organisation for code and game changes: 

The work will be distributed into 3 parts which will be allocated accordingly. 

MonsterAI: Kaiyuan Cui

Quality of Life/Game immersion: Natasha Ngo

Game mechanics: John An

This allows for even contribution and members will help and contribute to the other parts when needed. We will ensure everyone has similarly distributed workload by actively communicating about the workflow and the progress to make sure no one is over/underworking during the evaluation process.


## Evaluation Report

TODO (due milestone 3) - see specification for details

## Shaders and Special Effects

TODO (due milestone 3) - see specification for details

## Summary of Contributions

TODO (due milestone 3) - see specification for details

## References and External Resources

TODO (to be continuously updated) - see specification for details
